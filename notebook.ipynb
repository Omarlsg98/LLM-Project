{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import data.loader as loader_module\n",
    "import evaluation.predict as predict_module\n",
    "import evaluation.eval as eval_module\n",
    "\n",
    "reload(predict_module)\n",
    "reload(eval_module)\n",
    "reload(loader_module)\n",
    "\n",
    "from evaluation.predict import ModelPredictor\n",
    "from evaluation.eval import evaluate_generation, evaluate_classification, get_confusion_matrix\n",
    "from data.loader import Dataset, get_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Rose had some kilograms of rice. She cooked 9/10 kilograms in the morning and 1/4 of the remaining in the evening. How many grams of rice did she have left?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Rose had some kilograms of rice. She cooked 9/10 kilograms in the morning and 1/4 of the remaining in the evening. How many grams of rice did she have left?',\n",
       " 'type': 'not enough information',\n",
       " 'base answer': 750.0,\n",
       " 'file_origin': 'replace.json'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = get_dataset(\n",
    "    10,\n",
    "    split_percentage=1.0,\n",
    "    percent_files=(0.34, 0.33, 0.33),\n",
    "    file_names=(\"base.json\", \"replace.json\", \"which.json\"),\n",
    ")\n",
    "print(len(train_set))\n",
    "print(train_set[-1])\n",
    "train_set.data[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'A lumberjack is chopping down trees so he can sell firewood. Each tree he chops produces 4 logs each, and each log is then chopped into 5 pieces of firewood. If the lumberjack has chopped 500 pieces of firewood, how many trees did he chop down?', 'type': 'enough information', 'base answer': 25.0, 'file_origin': 'base.json'}\n",
      "{'question': 'May can knit some scarves using one yarn. She bought 2 red yarns, 6 blue yarns, and 4 yellow yarns. How many scarves will she be able to make in total?', 'type': 'not enough information', 'base answer': 36.0, 'file_origin': 'replace.json'}\n",
      "{'question': 'Bill and Ted went into the forest to gather some wild mushrooms. Bill gathered 12 red mushrooms and 6 brown mushrooms.  Ted gathered 14 green mushrooms and 6 blue mushrooms.  If half of the blue mushrooms, two-thirds of the red mushrooms, and all of the brown mushrooms have white spots, how many white-spotted mushrooms did they gather?', 'type': 'enough information', 'base answer': 17.0, 'file_origin': 'base.json'}\n",
      "{'question': 'A 10 m long and 8 m wide rectangular floor is to be covered with a square carpet with 4 m sides. How many square meters of the floor are uncovered?', 'type': 'enough information', 'base answer': 64.0, 'file_origin': 'base.json'}\n",
      "{'question': 'Each month, Diego deposits his $5,000 paycheck into a bank account, which amount to $4,600 per month. How much, in dollars, does Diego save over the course of a year?', 'type': 'not enough information', 'base answer': 4800.0, 'file_origin': 'which.json'}\n",
      "{'question': 'The pet store can buy a goldfish for $.25 and sell it for $.75. The owner plans to use the profits from goldfish sales to buy a new tank. After one week, he is 45% short of the price. How many goldfish did he sell that week?', 'type': 'not enough information', 'base answer': 110.0, 'file_origin': 'which.json'}\n",
      "{'question': 'A library has a collection of 100 historical novels arranged on a shelf. 5 people borrow 2 books each from the shelf on a particular day,  and 20 more books are borrowed from the shelf on the second day. How many books are remaining on the shelf after the second day?', 'type': 'enough information', 'base answer': 70.0, 'file_origin': 'base.json'}\n",
      "{'question': 'Dolly wants to ride the Ferris wheel twice, the roller coaster three times, and the log ride seven times. The Ferris wheel costs 2 tickets, the roller coaster costs 5 tickets and the log ride costs 1 ticket. Dolly has some tickets. How many more tickets should Dolly buy?', 'type': 'not enough information', 'base answer': 6.0, 'file_origin': 'replace.json'}\n",
      "{'question': 'Sarah wants to start a cupcake business and was approved for a business loan.  The loan has 0% interest if she pays the entire amount back in 5 years.  If she put $10,000 down as a down payment and her monthly payments are $600.00, how much was her loan for (including the down payment)?', 'type': 'not enough information', 'base answer': 46000.0, 'file_origin': 'which.json'}\n",
      "{'question': 'Rose had some kilograms of rice. She cooked 9/10 kilograms in the morning and 1/4 of the remaining in the evening. How many grams of rice did she have left?', 'type': 'not enough information', 'base answer': 750.0, 'file_origin': 'replace.json'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(min(len(train_set), 10)):\n",
    "    print(train_set.data[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo-instruct\"\n",
    "model = ModelPredictor(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_numbers_from_text(text):\n",
    "    try:\n",
    "        return re.findall(\n",
    "                r\"(?<!\\S)(?=.)[\\$]?(-?(0|([1-9](\\d*|\\d{0,2}(,\\d{3})*))))?(\\.\\d*[1-9])?(?!\\S)\", text\n",
    "            )[-1][0]\n",
    "    except IndexError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['100', '12', '8', '32', '60,000', '90', '60', '38', '37,000', '482'],\n",
       " ['100 trees\\n',\n",
       "  '12',\n",
       "  '8',\n",
       "  '32',\n",
       "  '60,000',\n",
       "  '90',\n",
       "  '60',\n",
       "  '38',\n",
       "  '$37,000',\n",
       "  '482.5 grams'])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"What is the answer (just the number nothing else) for the following question:\n",
    "QUESTION: {question}\n",
    "ANSWER: \"\"\"\n",
    "\n",
    "results_generate, original = model.generate(\n",
    "    dataset=train_set,\n",
    "    prompt_template=prompt_template,\n",
    "    extract_function=extract_numbers_from_text, \n",
    "    num_samples=1,\n",
    "    num_tokens=5,\n",
    ")\n",
    "results_generate, original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No'],\n",
       " [' Yes', 'Yes', 'No ', 'No', ' No', 'No', 'Yes', 'No', 'Yes', ' No '])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_yes_or_no(text):\n",
    "    if \"yes\" in text.lower():\n",
    "        return \"Yes\"\n",
    "    elif \"no\" in text.lower():\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "classify_with_generation_template = \"\"\"Is there enough information to answer this question? \n",
    "QUESTION: {question}\n",
    "-- Only answer with yes or no --\n",
    "ANSWER: \"\"\"\n",
    "\n",
    "results_classify, original = model.generate(\n",
    "    dataset=train_set,\n",
    "    prompt_template=classify_with_generation_template,\n",
    "    extract_function=extract_yes_or_no, \n",
    "    num_samples=1,\n",
    "    num_tokens=5,\n",
    ")\n",
    "results_classify, original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This only works with certain older models!\n",
    "model_name = \"davinci-002\" \n",
    "model = ModelPredictor(model_name)\n",
    "\n",
    "classify_template = \"\"\"Is there enough information to answer this question? \n",
    "{question}\n",
    "ANSWER: {choice}\"\"\"\n",
    "choices = [\"No\", \"Yes\"]\n",
    "\n",
    "results_classify = model.classify(\n",
    "    dataset=train_set,\n",
    "    prompt_template=classify_template,\n",
    "    labels=choices,\n",
    "    return_probs=False,\n",
    ")\n",
    "results_classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output=  ['100', '12', '8', '32', '60,000', '90', '60', '38', '37,000', '482']\n",
      "ground truth=  [25.0, 36.0, 17.0, 64.0, 4800.0, 110.0, 70.0, 6.0, 46000.0, 750.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([False, False, False, False, False, False, False, False, False,\n",
       "        False]),\n",
       " 0.0)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model output= \", results_generate)\n",
    "print(\"ground truth= \", list(train_set.get_base_answer()))\n",
    "correct, accuracy = evaluate_generation(train_set, results_generate)\n",
    "correct, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No'],\n",
       " ['Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No'])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_choice_mapping = {\n",
    "    \"not enough information\": \"No\",\n",
    "    \"enough information\": \"Yes\",\n",
    "}\n",
    "results_classify, list(train_set.get_type(to_choice_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True, False, False, False,  True,  True,  True,  True, False,\n",
       "         True]),\n",
       " 0.6)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct, accuracy = evaluate_classification(\n",
    "    train_set,\n",
    "    results_classify, # type: ignore\n",
    "    to_choice_mapping=to_choice_mapping,\n",
    ")\n",
    "correct, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 2.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_confusion_matrix(\n",
    "    predict=[\"unknown\", \"10\", \"11\", \"9\", \"unknown\"],\n",
    "    original=[\"unknown\", \"9\", \"11\", \"unknown\", \"unknown\"],\n",
    "    unknown_value = \"unknown\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
